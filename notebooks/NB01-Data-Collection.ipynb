{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before we start\n",
    "## Set up python environment\n",
    "As per the README file, I set up my conda environment and installed my program libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this section if you haven't followed the directions in the README.md file yet.\n",
    "\n",
    "# !conda init\n",
    "# !conda create -n gymternet -- python 3.12\n",
    "# !conda activate gymternet \n",
    "# !conda install pip -y\n",
    "# !pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and programs\n",
    "\n",
    "Now that we're operating in Python, install all the libraries etc called on in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from scrapy import Selector\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint as print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting program-level variables\n",
    "driver = webdriver.Chrome()\n",
    "years = [2024, 2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016, 2015] # These are the years that we are interested in evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing as I'm fetching a large quantity of data and my internet can be patchy, I want a method to fetch pages that includes error handling, and records unsuccessful attempts to reach a url, so that I can go back later and retry if necessary (and if I have time).\n",
    "\n",
    "Much of the error handling code was provided by copilot, and seems to be unproblematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_logs = []\n",
    "\n",
    "def fetch_page(url, retries=3, timeout=10):\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=timeout)\n",
    "            if response.status_code == 200:\n",
    "                return response.text\n",
    "            else:\n",
    "                error_logs.append({\n",
    "                    'url': url,\n",
    "                    'status_code': response.status_code,\n",
    "                    'error': 'Non-200 status code',\n",
    "                    'timestamp': datetime.datetime.now().isoformat()\n",
    "                })\n",
    "        except requests.exceptions.Timeout:\n",
    "            error_logs.append({\n",
    "                'url': url,\n",
    "                'status_code': None,\n",
    "                'error': 'Timeout',\n",
    "                'timestamp': datetime.datetime.now().isoformat()\n",
    "            })\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            error_logs.append({\n",
    "                'url': url,\n",
    "                'status_code': None,\n",
    "                'error': str(e),\n",
    "                'timestamp': datetime.datetime.now().isoformat()\n",
    "            })\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Get the team info\n",
    "The first step in the logic is to start to set up the data related to the teams. The teams are the 'base unit' of analysis for these data: all meets comprise teams, all gymnasts belong to teams, all scores either belong to gymnasts who belong to teams, or belong to teams directly.\n",
    "\n",
    "On the landing page, I have scraped all the information for the past 10 years; teams are relatively static, but occassionally there will be a new team added to the roster, or a team dropped, so at this stage I'll just grab everything and drop duplicates later.\n",
    "\n",
    "## 1.1 Scraping the data\n",
    "The roadtonationals.com website has hidden apis, which are visible when inspecting using the 'Network' tab. With the help of [Postman](https://www.postman.com/), I was able to establish that no specific headers were needed, and to get the code needed to scrape that data.\n",
    "\n",
    "It was evident from previewing that cycling through the years was as simple as replacing the final component of the cURL slug with the year in question.\n",
    "\n",
    "In the interest of not having to run this code repeatedly, I saved the data down to a json file that I can easily read to a DataFrame locally.\n",
    "\n",
    "**NB: The raw data that is written from this is saved in the 'data/raw/teams' folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_url_root = \"https://www.roadtonationals.com/api/women/finalresults/\"\n",
    "\n",
    "# For every year, access the website and save the data to a json file\n",
    "def get_the_teams(url, year):\n",
    "    year_url = year_url_root + str(year)\n",
    "\n",
    "    # Code here generated by Postman\n",
    "    payload = {}\n",
    "    headers = {\n",
    "        'Cookie': 'PHPSESSID=c48eb24102c0c45390a5d64809741f95'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", year_url, headers=headers, data=payload)\n",
    "\n",
    "    # Save the data to a json file\n",
    "    with open(f'../data/raw/teams/{year}_teams.json', 'w') as f:\n",
    "        # pure text\n",
    "        f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to get the team info for every year\n",
    "for year in years:\n",
    "    get_the_teams(year_url_root, year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Get the meet info\n",
    "The next phase in the logic is collecting all the information about all the meets that have happened between teams in the last 10 years. An easy way to find this information is to visit every team's dashboard (eg. [Florida] (https://roadtonationals.com/results/teams/dashboard/2024/22)), and cycle through the years to collect all the data.\n",
    "\n",
    "## 2.1 Setting up to scrape\n",
    "Like the team data, the cURL patterns for this process were fairly easy to establish, with the last section of the slug being the team id and the second to last section being the year.\n",
    "\n",
    "But to cycle through this pattern, I needed to first get a list of the team ids, which are helpfully stored in the teams json files, but not readable in the program yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the teams json files into a DataFrame\n",
    "\n",
    "# Create an empty DataFrame\n",
    "teams_data_df = pd.DataFrame()\n",
    "\n",
    "# For every year, load the data from the json file and append to the DataFrame\n",
    "for year in years:\n",
    "    filename = f'../data/raw/teams/{year}_teams.json'\n",
    "\n",
    "    # Read the json file into a temporary df\n",
    "    temp_df = pd.read_json(filename)\n",
    "    temp_df['year'] = year\n",
    "\n",
    "    # Append the temporary df to the main df\n",
    "    teams_data_df = pd.concat([teams_data_df, temp_df])\n",
    "\n",
    "\n",
    "teams_data_df = teams_data_df.reset_index(drop=True)\n",
    "teams_df = pd.json_normalize(teams_data_df['data']).reset_index(drop=True)\n",
    "teams_df['year'] = teams_data_df['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>team_name</th>\n",
       "      <th>team_id</th>\n",
       "      <th>ncaa_final</th>\n",
       "      <th>ncaa</th>\n",
       "      <th>nqs</th>\n",
       "      <th>regionals</th>\n",
       "      <th>rqs</th>\n",
       "      <th>division_id</th>\n",
       "      <th>average_score</th>\n",
       "      <th>high_score</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>LSU</td>\n",
       "      <td>34</td>\n",
       "      <td>198.225</td>\n",
       "      <td>198.113</td>\n",
       "      <td>396.465</td>\n",
       "      <td>198.250</td>\n",
       "      <td>198.215</td>\n",
       "      <td>1</td>\n",
       "      <td>197.908</td>\n",
       "      <td>198.475</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>California</td>\n",
       "      <td>15</td>\n",
       "      <td>197.850</td>\n",
       "      <td>197.713</td>\n",
       "      <td>396.455</td>\n",
       "      <td>198.275</td>\n",
       "      <td>198.180</td>\n",
       "      <td>1</td>\n",
       "      <td>197.833</td>\n",
       "      <td>198.550</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Utah</td>\n",
       "      <td>69</td>\n",
       "      <td>197.800</td>\n",
       "      <td>197.938</td>\n",
       "      <td>395.470</td>\n",
       "      <td>197.575</td>\n",
       "      <td>197.895</td>\n",
       "      <td>1</td>\n",
       "      <td>197.704</td>\n",
       "      <td>198.300</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Florida</td>\n",
       "      <td>22</td>\n",
       "      <td>197.438</td>\n",
       "      <td>197.875</td>\n",
       "      <td>396.230</td>\n",
       "      <td>198.325</td>\n",
       "      <td>197.905</td>\n",
       "      <td>1</td>\n",
       "      <td>197.670</td>\n",
       "      <td>198.225</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>61</td>\n",
       "      <td>None</td>\n",
       "      <td>197.075</td>\n",
       "      <td>394.620</td>\n",
       "      <td>197.575</td>\n",
       "      <td>197.045</td>\n",
       "      <td>1</td>\n",
       "      <td>196.563</td>\n",
       "      <td>197.975</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rank   team_name team_id ncaa_final     ncaa      nqs regionals      rqs  \\\n",
       "0    1         LSU      34    198.225  198.113  396.465   198.250  198.215   \n",
       "1    2  California      15    197.850  197.713  396.455   198.275  198.180   \n",
       "2    3        Utah      69    197.800  197.938  395.470   197.575  197.895   \n",
       "3    4     Florida      22    197.438  197.875  396.230   198.325  197.905   \n",
       "4    5    Stanford      61       None  197.075  394.620   197.575  197.045   \n",
       "\n",
       "  division_id average_score high_score  year  \n",
       "0           1       197.908    198.475  2024  \n",
       "1           1       197.833    198.550  2024  \n",
       "2           1       197.704    198.300  2024  \n",
       "3           1       197.670    198.225  2024  \n",
       "4           1       196.563    197.975  2024  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the df\n",
    "teams_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll do some light data cleaning now so that it's easier to look at what I'm looking at and to get rid of irrelevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns that we are not interested in\n",
    "teams_df = teams_df.drop(columns=['rank', 'ncaa_final', 'nqs', 'regionals', 'rqs', 'division_id', 'average_score', 'high_score', 'ncaa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_name</th>\n",
       "      <th>team_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSU</td>\n",
       "      <td>34</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>California</td>\n",
       "      <td>15</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Utah</td>\n",
       "      <td>69</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Florida</td>\n",
       "      <td>22</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stanford</td>\n",
       "      <td>61</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    team_name team_id  year\n",
       "0         LSU      34  2024\n",
       "1  California      15  2024\n",
       "2        Utah      69  2024\n",
       "3     Florida      22  2024\n",
       "4    Stanford      61  2024"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the df\n",
    "teams_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates - ie. if team_id & team_name are identical, retain years as a list\n",
    "teams_df = teams_df.drop_duplicates(subset=['team_id', 'team_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the df\n",
    "teams_df.dtypes\n",
    "teams_df['team_id'] = teams_df['team_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the link to access the team's dashboard\n",
    "# Note: this accesses the api for the most recent dashboard for each team. If you want to access a specific year, you will need to modify the URL\n",
    "base_team_url = str('https://www.roadtonationals.com/api/women/dashboard')\n",
    "\n",
    "# Add the team links to the team_url column\n",
    "teams_df['team_url'] = teams_df.apply(lambda x: f'{base_team_url}/{str(x[\"year\"])}/{str(x[\"team_id\"])}', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     https://www.roadtonationals.com/api/women/dash...\n",
       "1     https://www.roadtonationals.com/api/women/dash...\n",
       "2     https://www.roadtonationals.com/api/women/dash...\n",
       "3     https://www.roadtonationals.com/api/women/dash...\n",
       "4     https://www.roadtonationals.com/api/women/dash...\n",
       "                            ...                        \n",
       "84    https://www.roadtonationals.com/api/women/dash...\n",
       "85    https://www.roadtonationals.com/api/women/dash...\n",
       "86    https://www.roadtonationals.com/api/women/dash...\n",
       "87    https://www.roadtonationals.com/api/women/dash...\n",
       "88    https://www.roadtonationals.com/api/women/dash...\n",
       "Name: team_url, Length: 89, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the df - this looks good to work with now\n",
    "teams_df['team_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the teams_df for easy access in later notebooks\n",
    "teams_df.to_pickle('../data/raw/dirty_dfs/teams_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Scraping the meet data\n",
    "\n",
    "As with the teams data, once the location of the hidden api was found, it was simple enough to establish the pattern of the curl, so again, building the specific link was folded into the method for fetching, reading and saving the content.\n",
    "\n",
    "**NB: The raw data that is written from this is saved in the 'data/raw/meets' folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all team dashboards across all years and teams \n",
    "meet_urls = teams_df['team_url'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the meet info for every team in every year\n",
    "def get_the_meet_info(url):\n",
    "    year = url.split('/')[-2]\n",
    "    team = url.split('/')[-1]\n",
    "    # If we are able to fetch the page without timing out\n",
    "    if fetch_page(url):   \n",
    "        payload = {}\n",
    "        headers = {\n",
    "                'Cookie': 'PHPSESSID=c48eb24102c0c45390a5d64809741f95'\n",
    "                }\n",
    "\n",
    "        response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "        # Save the data to a json file\n",
    "        with open(f'../data/raw/meets/{year}_{team}_meets.json', 'w') as f:\n",
    "            # pure text\n",
    "            f.write(response.text)\n",
    "    else:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching up the meet_urls to avoid overloading the server\n",
    "batch_size = 100\n",
    "batches = [meet_urls[i:i + batch_size] for i in range(0, len(meet_urls), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the method for every url in the list\n",
    "\n",
    "# #Batch 1 #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[0]):\n",
    "\n",
    "#     get_the_meet_info(url)\n",
    "\n",
    "# #Batch 2 #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[1]): \n",
    "\n",
    "#     get_the_meet_info(url)\n",
    "\n",
    "# #Batch 3  #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[2]):\n",
    "\n",
    "#     get_the_meet_info(url)\n",
    "\n",
    "# #Batch 4  #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[3]):\n",
    "\n",
    "#     get_the_meet_info(url)\n",
    "\n",
    "# #Batch 5 #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[4]):\n",
    "\n",
    "#     get_the_meet_info(url)\n",
    "\n",
    "# #Batch 6  #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[5]):\n",
    "\n",
    "#     get_the_meet_info(url)\n",
    "\n",
    "# #Batch 7   #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[6]):\n",
    "\n",
    "#     get_the_meet_info(url)\n",
    "\n",
    "# #Batch 8   #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[7]):\n",
    "\n",
    "#     get_the_meet_info(url)\n",
    "\n",
    "#Batch 9  #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[8]):\n",
    "\n",
    "#     get_the_meet_info(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the json files into a DataFrame\n",
    "\n",
    "# Create an empty DataFrame\n",
    "team_ids = teams_df['team_id'].tolist()\n",
    "meets_data_df = pd.DataFrame()\n",
    "\n",
    "with open(filename) as data_file:    \n",
    "    data = json.load(data_file)  \n",
    "\n",
    "\n",
    "# For every year, load the data from the json file and append to the DataFrame\n",
    "for year in years:\n",
    "    for team in team_ids:\n",
    "        filename = f'../data/raw/meets/{year}_{team}_meets.json'\n",
    "\n",
    "        with open(filename) as data_file:    \n",
    "            data = json.load(data_file) \n",
    "\n",
    "            # Read the json file into a temporary df\n",
    "            temp_df = pd.json_normalize(data, 'meets')\n",
    "            temp_df['year'] = year\n",
    "            temp_df['team_id'] = team\n",
    "\n",
    "            # Append the temporary df to the main df\n",
    "            meets_data_df = pd.concat([meets_data_df, temp_df])\n",
    "\n",
    "\n",
    "meets_data_df = meets_data_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_id</th>\n",
       "      <th>team_name</th>\n",
       "      <th>meet_id</th>\n",
       "      <th>meet_date</th>\n",
       "      <th>team_score</th>\n",
       "      <th>home</th>\n",
       "      <th>opponent</th>\n",
       "      <th>meet_desc</th>\n",
       "      <th>linked_id</th>\n",
       "      <th>jas</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>69</td>\n",
       "      <td>Utah</td>\n",
       "      <td>30231</td>\n",
       "      <td>Sat, Apr-20-2024</td>\n",
       "      <td>197.8000</td>\n",
       "      <td>A</td>\n",
       "      <td>California, Florida, LSU</td>\n",
       "      <td>NCAA Championships Finals</td>\n",
       "      <td>6392</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>22</td>\n",
       "      <td>Florida</td>\n",
       "      <td>30230</td>\n",
       "      <td>Sat, Apr-20-2024</td>\n",
       "      <td>197.4375</td>\n",
       "      <td>A</td>\n",
       "      <td>California, LSU, Utah</td>\n",
       "      <td>NCAA Championships Finals</td>\n",
       "      <td>6392</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15</td>\n",
       "      <td>California</td>\n",
       "      <td>30226</td>\n",
       "      <td>Sat, Apr-20-2024</td>\n",
       "      <td>197.8500</td>\n",
       "      <td>A</td>\n",
       "      <td>Florida, LSU, Utah</td>\n",
       "      <td>NCAA Championships Finals</td>\n",
       "      <td>6392</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>34</td>\n",
       "      <td>LSU</td>\n",
       "      <td>30225</td>\n",
       "      <td>Sat, Apr-20-2024</td>\n",
       "      <td>198.2250</td>\n",
       "      <td>A</td>\n",
       "      <td>California, Florida, Utah</td>\n",
       "      <td>NCAA Championships Finals</td>\n",
       "      <td>6392</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>33</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>30224</td>\n",
       "      <td>Thu, Apr-18-2024</td>\n",
       "      <td>19.9000</td>\n",
       "      <td>A</td>\n",
       "      <td>Alabama, Arizona State, Arkansas, Boise State,...</td>\n",
       "      <td>NCAA Championships</td>\n",
       "      <td>6391</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     team_id   team_name meet_id         meet_date team_score home  \\\n",
       "48        69        Utah   30231  Sat, Apr-20-2024   197.8000    A   \n",
       "63        22     Florida   30230  Sat, Apr-20-2024   197.4375    A   \n",
       "32        15  California   30226  Sat, Apr-20-2024   197.8500    A   \n",
       "15        34         LSU   30225  Sat, Apr-20-2024   198.2250    A   \n",
       "139       33    Kentucky   30224  Thu, Apr-18-2024    19.9000    A   \n",
       "\n",
       "                                              opponent  \\\n",
       "48                            California, Florida, LSU   \n",
       "63                               California, LSU, Utah   \n",
       "32                                  Florida, LSU, Utah   \n",
       "15                           California, Florida, Utah   \n",
       "139  Alabama, Arizona State, Arkansas, Boise State,...   \n",
       "\n",
       "                     meet_desc linked_id jas  year  \n",
       "48   NCAA Championships Finals      6392      2024  \n",
       "63   NCAA Championships Finals      6392      2024  \n",
       "32   NCAA Championships Finals      6392      2024  \n",
       "15   NCAA Championships Finals      6392      2024  \n",
       "139         NCAA Championships      6391      2024  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the df\n",
    "meets_data_df.sort_values(by='meet_id', ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_id</th>\n",
       "      <th>team_name</th>\n",
       "      <th>meet_id</th>\n",
       "      <th>meet_date</th>\n",
       "      <th>team_score</th>\n",
       "      <th>home</th>\n",
       "      <th>opponent</th>\n",
       "      <th>meet_desc</th>\n",
       "      <th>linked_id</th>\n",
       "      <th>jas</th>\n",
       "      <th>year</th>\n",
       "      <th>meet_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>LSU</td>\n",
       "      <td>28977</td>\n",
       "      <td>Fri, Jan-05-2024</td>\n",
       "      <td>196.9750</td>\n",
       "      <td>H</td>\n",
       "      <td>Ohio State</td>\n",
       "      <td></td>\n",
       "      <td>5986</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.roadtonationals.com/api/women/meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>LSU</td>\n",
       "      <td>29040</td>\n",
       "      <td>Sat, Jan-13-2024</td>\n",
       "      <td>197.1500</td>\n",
       "      <td>A</td>\n",
       "      <td>Oklahoma, UCLA, Utah</td>\n",
       "      <td>Sprouts Farmers Market Collegiate Quad</td>\n",
       "      <td>6011</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.roadtonationals.com/api/women/meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>LSU</td>\n",
       "      <td>29098</td>\n",
       "      <td>Fri, Jan-19-2024</td>\n",
       "      <td>198.1250</td>\n",
       "      <td>H</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td></td>\n",
       "      <td>6030</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.roadtonationals.com/api/women/meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>LSU</td>\n",
       "      <td>29215</td>\n",
       "      <td>Fri, Jan-26-2024</td>\n",
       "      <td>197.2250</td>\n",
       "      <td>A</td>\n",
       "      <td>Missouri</td>\n",
       "      <td></td>\n",
       "      <td>6078</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.roadtonationals.com/api/women/meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>LSU</td>\n",
       "      <td>29303</td>\n",
       "      <td>Fri, Feb-02-2024</td>\n",
       "      <td>198.4750</td>\n",
       "      <td>H</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td></td>\n",
       "      <td>6111</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.roadtonationals.com/api/women/meet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   team_id team_name meet_id         meet_date team_score home  \\\n",
       "0       34       LSU   28977  Fri, Jan-05-2024   196.9750    H   \n",
       "1       34       LSU   29040  Sat, Jan-13-2024   197.1500    A   \n",
       "2       34       LSU   29098  Fri, Jan-19-2024   198.1250    H   \n",
       "3       34       LSU   29215  Fri, Jan-26-2024   197.2250    A   \n",
       "4       34       LSU   29303  Fri, Feb-02-2024   198.4750    H   \n",
       "\n",
       "               opponent                               meet_desc linked_id jas  \\\n",
       "0            Ohio State                                              5986       \n",
       "1  Oklahoma, UCLA, Utah  Sprouts Farmers Market Collegiate Quad      6011       \n",
       "2              Kentucky                                              6030       \n",
       "3              Missouri                                              6078       \n",
       "4              Arkansas                                              6111       \n",
       "\n",
       "   year                                           meet_url  \n",
       "0  2024  https://www.roadtonationals.com/api/women/meet...  \n",
       "1  2024  https://www.roadtonationals.com/api/women/meet...  \n",
       "2  2024  https://www.roadtonationals.com/api/women/meet...  \n",
       "3  2024  https://www.roadtonationals.com/api/women/meet...  \n",
       "4  2024  https://www.roadtonationals.com/api/women/meet...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the meet url to the DataFrame\n",
    "results_url_root = \"https://www.roadtonationals.com/api/women/meetresults/\"\n",
    "meets_data_df['meet_url'] = meets_data_df['meet_id'].apply(lambda x: f\"{results_url_root}{str(x)}\")\n",
    "\n",
    "# Preview the df\n",
    "meets_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the website I'm scraping from allocates a different meet_id for the same meet depending on which team is the originating source, so this df has a lot of duplicates that are difficult to spot. Luckily, there are only some 10,000 to sort through, so this should be no problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_id</th>\n",
       "      <th>team_name</th>\n",
       "      <th>meet_id</th>\n",
       "      <th>meet_date</th>\n",
       "      <th>team_score</th>\n",
       "      <th>home</th>\n",
       "      <th>opponent</th>\n",
       "      <th>meet_desc</th>\n",
       "      <th>linked_id</th>\n",
       "      <th>jas</th>\n",
       "      <th>year</th>\n",
       "      <th>meet_url</th>\n",
       "      <th>all_teams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>LSU</td>\n",
       "      <td>28977</td>\n",
       "      <td>Fri, Jan-05-2024</td>\n",
       "      <td>196.9750</td>\n",
       "      <td>H</td>\n",
       "      <td>Ohio State</td>\n",
       "      <td></td>\n",
       "      <td>5986</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.roadtonationals.com/api/women/meet...</td>\n",
       "      <td>(LSU, Ohio State)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>LSU</td>\n",
       "      <td>29040</td>\n",
       "      <td>Sat, Jan-13-2024</td>\n",
       "      <td>197.1500</td>\n",
       "      <td>A</td>\n",
       "      <td>Oklahoma, UCLA, Utah</td>\n",
       "      <td>Sprouts Farmers Market Collegiate Quad</td>\n",
       "      <td>6011</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.roadtonationals.com/api/women/meet...</td>\n",
       "      <td>(LSU, Oklahoma, UCLA, Utah)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>LSU</td>\n",
       "      <td>29098</td>\n",
       "      <td>Fri, Jan-19-2024</td>\n",
       "      <td>198.1250</td>\n",
       "      <td>H</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td></td>\n",
       "      <td>6030</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.roadtonationals.com/api/women/meet...</td>\n",
       "      <td>(Kentucky, LSU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>LSU</td>\n",
       "      <td>29215</td>\n",
       "      <td>Fri, Jan-26-2024</td>\n",
       "      <td>197.2250</td>\n",
       "      <td>A</td>\n",
       "      <td>Missouri</td>\n",
       "      <td></td>\n",
       "      <td>6078</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.roadtonationals.com/api/women/meet...</td>\n",
       "      <td>(LSU, Missouri)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>LSU</td>\n",
       "      <td>29303</td>\n",
       "      <td>Fri, Feb-02-2024</td>\n",
       "      <td>198.4750</td>\n",
       "      <td>H</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td></td>\n",
       "      <td>6111</td>\n",
       "      <td></td>\n",
       "      <td>2024</td>\n",
       "      <td>https://www.roadtonationals.com/api/women/meet...</td>\n",
       "      <td>(Arkansas, LSU)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   team_id team_name meet_id         meet_date team_score home  \\\n",
       "0       34       LSU   28977  Fri, Jan-05-2024   196.9750    H   \n",
       "1       34       LSU   29040  Sat, Jan-13-2024   197.1500    A   \n",
       "2       34       LSU   29098  Fri, Jan-19-2024   198.1250    H   \n",
       "3       34       LSU   29215  Fri, Jan-26-2024   197.2250    A   \n",
       "4       34       LSU   29303  Fri, Feb-02-2024   198.4750    H   \n",
       "\n",
       "               opponent                               meet_desc linked_id jas  \\\n",
       "0            Ohio State                                              5986       \n",
       "1  Oklahoma, UCLA, Utah  Sprouts Farmers Market Collegiate Quad      6011       \n",
       "2              Kentucky                                              6030       \n",
       "3              Missouri                                              6078       \n",
       "4              Arkansas                                              6111       \n",
       "\n",
       "   year                                           meet_url  \\\n",
       "0  2024  https://www.roadtonationals.com/api/women/meet...   \n",
       "1  2024  https://www.roadtonationals.com/api/women/meet...   \n",
       "2  2024  https://www.roadtonationals.com/api/women/meet...   \n",
       "3  2024  https://www.roadtonationals.com/api/women/meet...   \n",
       "4  2024  https://www.roadtonationals.com/api/women/meet...   \n",
       "\n",
       "                     all_teams  \n",
       "0            (LSU, Ohio State)  \n",
       "1  (LSU, Oklahoma, UCLA, Utah)  \n",
       "2              (Kentucky, LSU)  \n",
       "3              (LSU, Missouri)  \n",
       "4              (Arkansas, LSU)  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column that stores the team name and the opponent names as a sorted list\n",
    "meets_data_df['all_teams'] = meets_data_df.apply(lambda x: [x['team_name']] + x['opponent'].split(', '), axis=1)\n",
    "\n",
    "# Sort the list of team names alphabetically so they can be easily compared\n",
    "meets_data_df['all_teams'] = meets_data_df['all_teams'].apply(lambda x: sorted(x))\n",
    "\n",
    "# Convert the list of team names to a tuple so it can be used as a key to identify duplicates\n",
    "meets_data_df['all_teams'] = meets_data_df['all_teams'].apply(tuple)\n",
    "\n",
    "# Drop duplicates (when all_teams and meet_date column are identical, they are duplicates.\n",
    "meets_df = meets_data_df.drop_duplicates(subset=['all_teams', 'meet_date']).reset_index(drop=True)\n",
    "\n",
    "# Preview the df\n",
    "meets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the meets_df for easy access in later notebooks\n",
    "meets_df.to_pickle('../data/raw/dirty_dfs/meets_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_url_root = \"https://www.roadtonationals.com/api/women/meetresults/\"\n",
    "results_links = meets_df['meet_url'].tolist()\n",
    "\n",
    "# Get the results info for every meet\n",
    "def get_the_results_info(url):\n",
    "    meet_id = url.split('/')[-1]\n",
    "    # If we are able to fetch the page without timing out\n",
    "    if fetch_page(url):   \n",
    "        payload = {}\n",
    "        headers = {\n",
    "                'Cookie': 'PHPSESSID=c48eb24102c0c45390a5d64809741f95'\n",
    "                }\n",
    "\n",
    "        response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "        # Save the data to a json file\n",
    "        with open(f'../data/raw/results/{meet_id}_results.json', 'w') as f:\n",
    "            # pure text\n",
    "            f.write(response.text)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note for players at home - this will take a while to run (approx ~1 hr)\n",
    "# Complete data as at 2024-05-25 14:30:00 UTC is available in the '../data/raw/results' directory\n",
    "\n",
    "# Call the method for every url in the list\n",
    "\n",
    "# for url in results_links: #Commented out to avoid re-running\n",
    "\n",
    "#     get_the_results_info(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Error decoding JSON from file ../data/raw/results/27977_results.json: '\n",
      " 'Expecting value: line 1 column 1 (char 0)')\n",
      "('Error decoding JSON from file ../data/raw/results/26843_results.json: '\n",
      " 'Expecting value: line 1 column 1 (char 0)')\n",
      "('Error decoding JSON from file ../data/raw/results/24822_results.json: '\n",
      " 'Expecting value: line 1 column 1 (char 0)')\n",
      "('Error decoding JSON from file ../data/raw/results/21326_results.json: '\n",
      " 'Expecting value: line 1 column 1 (char 0)')\n",
      "('Error decoding JSON from file ../data/raw/results/20001_results.json: '\n",
      " 'Expecting value: line 1 column 1 (char 0)')\n",
      "('Error decoding JSON from file ../data/raw/results/19660_results.json: '\n",
      " 'Expecting value: line 1 column 1 (char 0)')\n",
      "('Error decoding JSON from file ../data/raw/results/20016_results.json: '\n",
      " 'Expecting value: line 1 column 1 (char 0)')\n"
     ]
    }
   ],
   "source": [
    "# Read the json files into a results DataFrame\n",
    "meet_ids = meets_df['meet_id'].tolist()\n",
    "\n",
    "# Create an empty DataFrame\n",
    "team_results_data_df = pd.DataFrame()\n",
    "gymnasts_data_df = pd.DataFrame()\n",
    "\n",
    "# with open(filename) as data_file:    \n",
    "#     data = json.load(data_file)  \n",
    "\n",
    "\n",
    "# For every meet, load the data from the results json file and append to the DataFrame\n",
    "for meet_id in meet_ids:\n",
    "    filename = f'../data/raw/results/{meet_id}_results.json'\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        if os.path.getsize(filename) == 0:\n",
    "            print(f\"File {filename} is empty.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with open(filename) as data_file:\n",
    "                data = json.load(data_file)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from file {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Read the json file into temporary DataFrames\n",
    "        temp_team_df = pd.json_normalize(data, 'teams')\n",
    "\n",
    "        # Normalising the scores data\n",
    "        scores_data = data['scores']\n",
    "\n",
    "        # Flatten the nested structure\n",
    "        # Since 'scores' is a list of lists, we need to flatten it first\n",
    "        flattened_scores = [item for sublist in scores_data for item in sublist]\n",
    "\n",
    "        # Create DataFrame\n",
    "        temp_gymnast_df = pd.json_normalize(flattened_scores)\n",
    "        temp_gymnast_df['meet_id'] = meet_id\n",
    "\n",
    "        # Append the temporary DataFrames to the main DataFrames\n",
    "        team_results_data_df = pd.concat([team_results_data_df, temp_team_df])\n",
    "        gymnasts_data_df = pd.concat([gymnasts_data_df, temp_gymnast_df])\n",
    "    \n",
    "    else:\n",
    "        print(f\"File {filename} does not exist.\")\n",
    "        continue\n",
    "\n",
    "# Reset index for the final DataFrames\n",
    "team_results_data_df = team_results_data_df.reset_index(drop=True)\n",
    "gymnasts_data_df = gymnasts_data_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see we have a (very manageable) number of failures. For the moment, I have enough data to get meaningful results, but I would like to come back at a later stage and see if the data are available but trying the process above with the (now deleted) meet_ids from the duplicates in the original `meets_data_df`, which I thankfully preserved.\n",
    "\n",
    "🚨 **TODO** - Come back to these errors and find the corresponding (duplicate) meets in the meets_data_df and check to see if the links work with the other meet_id\n",
    "\n",
    "✅ **UPDATE** - The error was due to some miscoding in the original source. No further action is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>tid</th>\n",
       "      <th>tname</th>\n",
       "      <th>vault</th>\n",
       "      <th>bars</th>\n",
       "      <th>beam</th>\n",
       "      <th>floor</th>\n",
       "      <th>tscore</th>\n",
       "      <th>year</th>\n",
       "      <th>home</th>\n",
       "      <th>lead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28977</td>\n",
       "      <td>34</td>\n",
       "      <td>LSU</td>\n",
       "      <td>49.3750</td>\n",
       "      <td>49.3750</td>\n",
       "      <td>48.7000</td>\n",
       "      <td>49.5250</td>\n",
       "      <td>196.9750</td>\n",
       "      <td>2024</td>\n",
       "      <td>H</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28978</td>\n",
       "      <td>46</td>\n",
       "      <td>Ohio State</td>\n",
       "      <td>49.3000</td>\n",
       "      <td>49.1250</td>\n",
       "      <td>49.0500</td>\n",
       "      <td>49.3000</td>\n",
       "      <td>196.7750</td>\n",
       "      <td>2024</td>\n",
       "      <td>A</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29039</td>\n",
       "      <td>47</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>49.4500</td>\n",
       "      <td>49.4500</td>\n",
       "      <td>49.5250</td>\n",
       "      <td>49.4750</td>\n",
       "      <td>197.9000</td>\n",
       "      <td>2024</td>\n",
       "      <td>A</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29040</td>\n",
       "      <td>34</td>\n",
       "      <td>LSU</td>\n",
       "      <td>49.2250</td>\n",
       "      <td>49.6500</td>\n",
       "      <td>48.7500</td>\n",
       "      <td>49.5250</td>\n",
       "      <td>197.1500</td>\n",
       "      <td>2024</td>\n",
       "      <td>A</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29042</td>\n",
       "      <td>66</td>\n",
       "      <td>UCLA</td>\n",
       "      <td>49.4000</td>\n",
       "      <td>49.2500</td>\n",
       "      <td>49.2500</td>\n",
       "      <td>49.2000</td>\n",
       "      <td>197.1000</td>\n",
       "      <td>2024</td>\n",
       "      <td>A</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mid tid       tname    vault     bars     beam    floor    tscore  year  \\\n",
       "0  28977  34         LSU  49.3750  49.3750  48.7000  49.5250  196.9750  2024   \n",
       "1  28978  46  Ohio State  49.3000  49.1250  49.0500  49.3000  196.7750  2024   \n",
       "2  29039  47    Oklahoma  49.4500  49.4500  49.5250  49.4750  197.9000  2024   \n",
       "3  29040  34         LSU  49.2250  49.6500  48.7500  49.5250  197.1500  2024   \n",
       "4  29042  66        UCLA  49.4000  49.2500  49.2500  49.2000  197.1000  2024   \n",
       "\n",
       "  home  lead  \n",
       "0    H  0.00  \n",
       "1    A  0.20  \n",
       "2    A  0.00  \n",
       "3    A  0.75  \n",
       "4    A  0.80  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the team results DataFrame\n",
    "team_results_data_df.head()\n",
    "\n",
    "# This one looks ok!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the team_results_data_df for easy access in later notebooks\n",
    "\n",
    "team_results_data_df.to_pickle('../data/raw/dirty_dfs/team_results_data_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gid</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>vault</th>\n",
       "      <th>bars</th>\n",
       "      <th>beam</th>\n",
       "      <th>floor</th>\n",
       "      <th>all_around</th>\n",
       "      <th>team_name</th>\n",
       "      <th>team_id</th>\n",
       "      <th>yr</th>\n",
       "      <th>vt_url</th>\n",
       "      <th>ub_url</th>\n",
       "      <th>bb_url</th>\n",
       "      <th>fx_url</th>\n",
       "      <th>meet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30950</td>\n",
       "      <td>Sierra</td>\n",
       "      <td>Ballard</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9.2000</td>\n",
       "      <td>9.9000</td>\n",
       "      <td>None</td>\n",
       "      <td>LSU</td>\n",
       "      <td>34</td>\n",
       "      <td>2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>28977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30952</td>\n",
       "      <td>Haleigh</td>\n",
       "      <td>Bryant</td>\n",
       "      <td>9.9500</td>\n",
       "      <td>9.8750</td>\n",
       "      <td>9.9250</td>\n",
       "      <td>9.9250</td>\n",
       "      <td>39.6750</td>\n",
       "      <td>LSU</td>\n",
       "      <td>34</td>\n",
       "      <td>2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>28977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31947</td>\n",
       "      <td>Ashley</td>\n",
       "      <td>Cowan</td>\n",
       "      <td>None</td>\n",
       "      <td>9.8000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LSU</td>\n",
       "      <td>34</td>\n",
       "      <td>2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>28977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32453</td>\n",
       "      <td>Amari</td>\n",
       "      <td>Drayton</td>\n",
       "      <td>9.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>LSU</td>\n",
       "      <td>34</td>\n",
       "      <td>2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>28977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30953</td>\n",
       "      <td>Olivia</td>\n",
       "      <td>Dunne</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9.8750</td>\n",
       "      <td>None</td>\n",
       "      <td>LSU</td>\n",
       "      <td>34</td>\n",
       "      <td>2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>28977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gid first_name last_name   vault    bars    beam   floor all_around  \\\n",
       "0  30950     Sierra   Ballard    None    None  9.2000  9.9000       None   \n",
       "1  30952    Haleigh    Bryant  9.9500  9.8750  9.9250  9.9250    39.6750   \n",
       "2  31947     Ashley     Cowan    None  9.8000    None    None       None   \n",
       "3  32453      Amari   Drayton  9.9250    None    None  9.9250       None   \n",
       "4  30953     Olivia     Dunne    None    None    None  9.8750       None   \n",
       "\n",
       "  team_name team_id    yr vt_url ub_url bb_url fx_url meet_id  \n",
       "0       LSU      34  2024   None   None   None   None   28977  \n",
       "1       LSU      34  2024   None   None   None   None   28977  \n",
       "2       LSU      34  2024   None   None   None   None   28977  \n",
       "3       LSU      34  2024   None   None   None   None   28977  \n",
       "4       LSU      34  2024   None   None   None   None   28977  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the gymnasts DataFrame\n",
    "\n",
    "gymnasts_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the gymnasts_data_df for easy access in later notebooks\n",
    "\n",
    "gymnasts_data_df.to_pickle('../data/raw/dirty_dfs/gymnasts_data_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
