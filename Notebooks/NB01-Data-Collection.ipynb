{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up shell environment\n",
    "Before we start, let's make sure our environment is set up to run all the code we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: osx-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Requirement already satisfied: attrs==23.2.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 1)) (23.2.0)\n",
      "Requirement already satisfied: Automat==22.10.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 2)) (22.10.0)\n",
      "Requirement already satisfied: certifi==2024.7.4 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 3)) (2024.7.4)\n",
      "Requirement already satisfied: cffi==1.16.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 5)) (3.3.2)\n",
      "Requirement already satisfied: colorama==0.4.6 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: constantly==23.10.4 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 7)) (23.10.4)\n",
      "Requirement already satisfied: cryptography==42.0.8 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 8)) (42.0.8)\n",
      "Requirement already satisfied: cssselect==1.2.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 10)) (0.7.1)\n",
      "Requirement already satisfied: filelock==3.15.4 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 11)) (3.15.4)\n",
      "Requirement already satisfied: h11==0.14.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 12)) (0.14.0)\n",
      "Requirement already satisfied: hyperlink==21.0.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 13)) (21.0.0)\n",
      "Requirement already satisfied: idna==3.7 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 14)) (3.7)\n",
      "Requirement already satisfied: incremental==22.10.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 15)) (22.10.0)\n",
      "Requirement already satisfied: itemadapter==0.9.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 16)) (0.9.0)\n",
      "Requirement already satisfied: itemloaders==1.3.1 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 17)) (1.3.1)\n",
      "Requirement already satisfied: jmespath==1.0.1 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 18)) (1.0.1)\n",
      "Requirement already satisfied: lets-plot==4.3.3 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 19)) (4.3.3)\n",
      "Requirement already satisfied: lxml==5.2.2 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 20)) (5.2.2)\n",
      "Requirement already satisfied: numerize==0.12 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 21)) (0.12)\n",
      "Collecting numpy==2.0.0 (from -r ../requirements.txt (line 22))\n",
      "  Using cached numpy-2.0.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: outcome==1.3.0.post0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 23)) (1.3.0.post0)\n",
      "Requirement already satisfied: packaging==24.1 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 24)) (24.1)\n",
      "Requirement already satisfied: palettable==3.3.3 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 25)) (3.3.3)\n",
      "Requirement already satisfied: pandas==2.2.2 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 26)) (2.2.2)\n",
      "Requirement already satisfied: parsel==1.9.1 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 27)) (1.9.1)\n",
      "Requirement already satisfied: Protego==0.3.1 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 28)) (0.3.1)\n",
      "Requirement already satisfied: pyasn1==0.6.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 29)) (0.6.0)\n",
      "Requirement already satisfied: pyasn1_modules==0.4.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 30)) (0.4.0)\n",
      "Requirement already satisfied: pycparser==2.22 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 31)) (2.22)\n",
      "Requirement already satisfied: PyDispatcher==2.0.7 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 32)) (2.0.7)\n",
      "Requirement already satisfied: pyOpenSSL==24.1.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 33)) (24.1.0)\n",
      "Requirement already satisfied: pypng==0.20220715.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 34)) (0.20220715.0)\n",
      "Requirement already satisfied: PySocks==1.7.1 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 35)) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 36)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2024.1 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 37)) (2024.1)\n",
      "Requirement already satisfied: queuelib==1.7.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 38)) (1.7.0)\n",
      "Requirement already satisfied: requests==2.32.3 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 39)) (2.32.3)\n",
      "Requirement already satisfied: requests-file==2.1.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 40)) (2.1.0)\n",
      "Requirement already satisfied: Scrapy==2.11.2 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 41)) (2.11.2)\n",
      "Requirement already satisfied: selenium==4.22.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 42)) (4.22.0)\n",
      "Requirement already satisfied: service-identity==24.1.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 43)) (24.1.0)\n",
      "Requirement already satisfied: six==1.16.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 44)) (1.16.0)\n",
      "Requirement already satisfied: sniffio==1.3.1 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 45)) (1.3.1)\n",
      "Requirement already satisfied: sortedcontainers==2.4.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 46)) (2.4.0)\n",
      "Requirement already satisfied: tldextract==5.1.2 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 47)) (5.1.2)\n",
      "Requirement already satisfied: tqdm==4.66.4 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 48)) (4.66.4)\n",
      "Requirement already satisfied: trio==0.26.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 49)) (0.26.0)\n",
      "Requirement already satisfied: trio-websocket==0.11.1 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 50)) (0.11.1)\n",
      "Requirement already satisfied: Twisted==24.3.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 51)) (24.3.0)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 53)) (4.12.2)\n",
      "Requirement already satisfied: tzdata==2024.1 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 54)) (2024.1)\n",
      "Requirement already satisfied: urllib3==2.2.2 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 55)) (2.2.2)\n",
      "Requirement already satisfied: w3lib==2.2.1 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 56)) (2.2.1)\n",
      "Requirement already satisfied: websocket-client==1.8.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 57)) (1.8.0)\n",
      "Requirement already satisfied: wsproto==1.2.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 58)) (1.2.0)\n",
      "Requirement already satisfied: zope.interface==6.4.post2 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from -r ../requirements.txt (line 59)) (6.4.post2)\n",
      "Requirement already satisfied: setuptools in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from Scrapy==2.11.2->-r ../requirements.txt (line 41)) (69.5.1)\n",
      "Using cached numpy-2.0.0-cp312-cp312-macosx_10_9_x86_64.whl (20.9 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.0.0\n",
      "Package                   Version\n",
      "------------------------- --------------\n",
      "anaconda-anon-usage       0.4.4\n",
      "anyio                     4.4.0\n",
      "appnope                   0.1.4\n",
      "archspec                  0.2.3\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.1\n",
      "async-lru                 2.0.4\n",
      "attrs                     23.2.0\n",
      "Automat                   22.10.0\n",
      "Babel                     2.15.0\n",
      "backoff                   2.2.1\n",
      "beautifulsoup4            4.12.3\n",
      "bleach                    6.1.0\n",
      "boltons                   23.0.0\n",
      "Bottleneck                1.3.7\n",
      "Brotli                    1.0.9\n",
      "certifi                   2024.7.4\n",
      "cffi                      1.16.0\n",
      "charset-normalizer        3.3.2\n",
      "colorama                  0.4.6\n",
      "comm                      0.2.2\n",
      "conda                     24.5.0\n",
      "conda-content-trust       0.2.0\n",
      "conda-libmamba-solver     24.1.0\n",
      "conda-package-handling    2.3.0\n",
      "conda_package_streaming   0.10.0\n",
      "constantly                23.10.4\n",
      "contourpy                 1.2.1\n",
      "cryptography              42.0.8\n",
      "cssselect                 1.2.0\n",
      "cycler                    0.12.1\n",
      "debugpy                   1.8.2\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "distro                    1.9.0\n",
      "executing                 2.0.1\n",
      "fastjsonschema            2.20.0\n",
      "filelock                  3.15.4\n",
      "fonttools                 4.53.1\n",
      "fqdn                      1.5.1\n",
      "frozendict                2.4.2\n",
      "greenlet                  3.0.3\n",
      "h11                       0.14.0\n",
      "httpcore                  1.0.5\n",
      "httpx                     0.27.0\n",
      "hyperlink                 21.0.0\n",
      "idna                      3.7\n",
      "incremental               22.10.0\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.26.0\n",
      "ipython-genutils          0.2.0\n",
      "ipywidgets                8.1.3\n",
      "isoduration               20.11.0\n",
      "itemadapter               0.9.0\n",
      "itemloaders               1.3.1\n",
      "jedi                      0.19.1\n",
      "Jinja2                    3.1.4\n",
      "jmespath                  1.0.1\n",
      "json5                     0.9.25\n",
      "jsonpatch                 1.33\n",
      "jsonpointer               2.1\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2023.12.1\n",
      "jupysql                   0.10.12\n",
      "jupysql-plugin            0.4.4\n",
      "jupyter                   1.0.0\n",
      "jupyter_client            8.6.2\n",
      "jupyter-console           6.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.10.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.14.1\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.2.3\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.2\n",
      "jupyterlab_widgets        3.0.11\n",
      "kiwisolver                1.4.5\n",
      "lets-plot                 4.3.3\n",
      "libmambapy                1.5.8\n",
      "lxml                      5.2.2\n",
      "MarkupSafe                2.1.5\n",
      "matplotlib                3.9.1\n",
      "matplotlib-inline         0.1.7\n",
      "menuinst                  2.1.1\n",
      "mistune                   3.0.2\n",
      "mkl-fft                   1.3.8\n",
      "mkl-random                1.2.4\n",
      "mkl-service               2.4.0\n",
      "monotonic                 1.6\n",
      "nbclient                  0.10.0\n",
      "nbconvert                 7.16.4\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "notebook                  7.2.1\n",
      "notebook_shim             0.2.4\n",
      "numerize                  0.12\n",
      "numexpr                   2.8.7\n",
      "numpy                     2.0.0\n",
      "outcome                   1.3.0.post0\n",
      "overrides                 7.7.0\n",
      "packaging                 24.1\n",
      "palettable                3.3.3\n",
      "pandas                    2.2.2\n",
      "pandocfilters             1.5.1\n",
      "parsel                    1.9.1\n",
      "parso                     0.8.4\n",
      "pexpect                   4.9.0\n",
      "pillow                    10.4.0\n",
      "pip                       24.0\n",
      "platformdirs              3.10.0\n",
      "ploomber-core             0.2.25\n",
      "ploomber-extension        0.1.1\n",
      "pluggy                    1.0.0\n",
      "posthog                   3.5.0\n",
      "prettytable               3.10.2\n",
      "prometheus_client         0.20.0\n",
      "prompt_toolkit            3.0.47\n",
      "Protego                   0.3.1\n",
      "psutil                    6.0.0\n",
      "ptyprocess                0.7.0\n",
      "pure-eval                 0.2.2\n",
      "pyasn1                    0.6.0\n",
      "pyasn1_modules            0.4.0\n",
      "pycosat                   0.6.6\n",
      "pycparser                 2.22\n",
      "PyDispatcher              2.0.7\n",
      "Pygments                  2.18.0\n",
      "pyOpenSSL                 24.1.0\n",
      "pyparsing                 3.1.2\n",
      "pypng                     0.20220715.0\n",
      "PySocks                   1.7.1\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        2.0.7\n",
      "pytz                      2024.1\n",
      "PyYAML                    6.0.1\n",
      "pyzmq                     26.0.3\n",
      "qtconsole                 5.5.2\n",
      "QtPy                      2.4.1\n",
      "queuelib                  1.7.0\n",
      "referencing               0.35.1\n",
      "requests                  2.32.3\n",
      "requests-file             2.1.0\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.19.0\n",
      "ruamel.yaml               0.17.21\n",
      "Scrapy                    2.11.2\n",
      "selenium                  4.22.0\n",
      "Send2Trash                1.8.3\n",
      "service-identity          24.1.0\n",
      "setuptools                69.5.1\n",
      "six                       1.16.0\n",
      "sniffio                   1.3.1\n",
      "sortedcontainers          2.4.0\n",
      "soupsieve                 2.5\n",
      "SQLAlchemy                2.0.31\n",
      "sqlglot                   25.6.1\n",
      "sqlparse                  0.5.1\n",
      "stack-data                0.6.3\n",
      "terminado                 0.18.1\n",
      "tinycss2                  1.3.0\n",
      "tldextract                5.1.2\n",
      "tornado                   6.4.1\n",
      "tqdm                      4.66.4\n",
      "traitlets                 5.14.3\n",
      "trio                      0.26.0\n",
      "trio-websocket            0.11.1\n",
      "truststore                0.8.0\n",
      "Twisted                   24.3.0\n",
      "types-python-dateutil     2.9.0.20240316\n",
      "typing_extensions         4.12.2\n",
      "tzdata                    2024.1\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.2.2\n",
      "w3lib                     2.2.1\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.6.0\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "wheel                     0.43.0\n",
      "widgetsnbextension        4.0.11\n",
      "wsproto                   1.2.0\n",
      "zope.interface            6.4.post2\n",
      "zstandard                 0.22.0\n"
     ]
    }
   ],
   "source": [
    "# conda create -n spiders-env python=3.11 -y\n",
    "# conda activate spiders-env\n",
    "\n",
    "!conda install pip -y\n",
    "!pip install -r ../requirements.txt\n",
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.0.1\n",
      "Uninstalling numpy-2.0.1:\n",
      "  Successfully uninstalled numpy-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.0.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "Collecting version\n",
      "  Downloading version-0.1.1.tar.gz (2.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[14 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/f6/yc2mppq57tq4fjfn7hmfsy0c0000gn/T/pip-install-ketck200/version_da09a45020bd4bfdba6f2e5b53f477b4/version.py:20: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  \u001b[31m   \u001b[0m   '(\\d+)\\.(\\d+)\\.(\\d+)'  # minor, major, patch\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/f6/yc2mppq57tq4fjfn7hmfsy0c0000gn/T/pip-install-ketck200/version_da09a45020bd4bfdba6f2e5b53f477b4/version.py:21: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \u001b[31m   \u001b[0m   '(-[0-9A-Za-z-\\.]+)?'  # pre-release\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/f6/yc2mppq57tq4fjfn7hmfsy0c0000gn/T/pip-install-ketck200/version_da09a45020bd4bfdba6f2e5b53f477b4/version.py:22: SyntaxWarning: invalid escape sequence '\\+'\n",
      "  \u001b[31m   \u001b[0m   '(\\+[0-9A-Za-z-\\.]+)?'  # build\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/f6/yc2mppq57tq4fjfn7hmfsy0c0000gn/T/pip-install-ketck200/version_da09a45020bd4bfdba6f2e5b53f477b4/setup.py\", line 4, in <module>\n",
      "  \u001b[31m   \u001b[0m     from version import __version__\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/f6/yc2mppq57tq4fjfn7hmfsy0c0000gn/T/pip-install-ketck200/version_da09a45020bd4bfdba6f2e5b53f477b4/version.py\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m     from itertools import izip_longest\n",
      "  \u001b[31m   \u001b[0m ImportError: cannot import name 'izip_longest' from 'itertools' (unknown location). Did you mean: 'zip_longest'?\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and programs\n",
    "\n",
    "Now that we're operating in Python, install all the libraries etc called on in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/f6/yc2mppq57tq4fjfn7hmfsy0c0000gn/T/ipykernel_63942/3100151271.py\", line 7, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/pandas/core/api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"/Users/jessicahyne/opt/miniconda3/lib/python3.12/site-packages/pandas/_libs/__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.12/site-packages/numpy/core/_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.12/site-packages/pandas/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     ArrowDtype,\n\u001b[1;32m     52\u001b[0m     Int8Dtype,\n\u001b[1;32m     53\u001b[0m     Int16Dtype,\n\u001b[1;32m     54\u001b[0m     Int32Dtype,\n\u001b[1;32m     55\u001b[0m     Int64Dtype,\n\u001b[1;32m     56\u001b[0m     UInt8Dtype,\n\u001b[1;32m     57\u001b[0m     UInt16Dtype,\n\u001b[1;32m     58\u001b[0m     UInt32Dtype,\n\u001b[1;32m     59\u001b[0m     UInt64Dtype,\n\u001b[1;32m     60\u001b[0m     Float32Dtype,\n\u001b[1;32m     61\u001b[0m     Float64Dtype,\n\u001b[1;32m     62\u001b[0m     CategoricalDtype,\n\u001b[1;32m     63\u001b[0m     PeriodDtype,\n\u001b[1;32m     64\u001b[0m     IntervalDtype,\n\u001b[1;32m     65\u001b[0m     DatetimeTZDtype,\n\u001b[1;32m     66\u001b[0m     StringDtype,\n\u001b[1;32m     67\u001b[0m     BooleanDtype,\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     NA,\n\u001b[1;32m     70\u001b[0m     isna,\n\u001b[1;32m     71\u001b[0m     isnull,\n\u001b[1;32m     72\u001b[0m     notna,\n\u001b[1;32m     73\u001b[0m     notnull,\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     Index,\n\u001b[1;32m     76\u001b[0m     CategoricalIndex,\n\u001b[1;32m     77\u001b[0m     RangeIndex,\n\u001b[1;32m     78\u001b[0m     MultiIndex,\n\u001b[1;32m     79\u001b[0m     IntervalIndex,\n\u001b[1;32m     80\u001b[0m     TimedeltaIndex,\n\u001b[1;32m     81\u001b[0m     DatetimeIndex,\n\u001b[1;32m     82\u001b[0m     PeriodIndex,\n\u001b[1;32m     83\u001b[0m     IndexSlice,\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     NaT,\n\u001b[1;32m     86\u001b[0m     Period,\n\u001b[1;32m     87\u001b[0m     period_range,\n\u001b[1;32m     88\u001b[0m     Timedelta,\n\u001b[1;32m     89\u001b[0m     timedelta_range,\n\u001b[1;32m     90\u001b[0m     Timestamp,\n\u001b[1;32m     91\u001b[0m     date_range,\n\u001b[1;32m     92\u001b[0m     bdate_range,\n\u001b[1;32m     93\u001b[0m     Interval,\n\u001b[1;32m     94\u001b[0m     interval_range,\n\u001b[1;32m     95\u001b[0m     DateOffset,\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     to_numeric,\n\u001b[1;32m     98\u001b[0m     to_datetime,\n\u001b[1;32m     99\u001b[0m     to_timedelta,\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     Flags,\n\u001b[1;32m    102\u001b[0m     Grouper,\n\u001b[1;32m    103\u001b[0m     factorize,\n\u001b[1;32m    104\u001b[0m     unique,\n\u001b[1;32m    105\u001b[0m     value_counts,\n\u001b[1;32m    106\u001b[0m     NamedAgg,\n\u001b[1;32m    107\u001b[0m     array,\n\u001b[1;32m    108\u001b[0m     Categorical,\n\u001b[1;32m    109\u001b[0m     set_eng_float_format,\n\u001b[1;32m    110\u001b[0m     Series,\n\u001b[1;32m    111\u001b[0m     DataFrame,\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.12/site-packages/pandas/core/api.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     NaT,\n\u001b[1;32m      3\u001b[0m     Period,\n\u001b[1;32m      4\u001b[0m     Timedelta,\n\u001b[1;32m      5\u001b[0m     Timestamp,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     ArrowDtype,\n\u001b[1;32m     11\u001b[0m     CategoricalDtype,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     PeriodDtype,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.12/site-packages/pandas/_libs/__init__.py:17\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     NaT,\n\u001b[1;32m     21\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     iNaT,\n\u001b[1;32m     27\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from scrapy import Selector\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint as print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting program-level variables\n",
    "driver = webdriver.Chrome()\n",
    "year_url_root = \"https://www.roadtonationals.com/api/women/finalresults/\"\n",
    "years = [2024, 2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016, 2015] # These are the years that we are interested in evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a fetch page function with a retry function and error handling\n",
    "# def fetch_page(url, retries=5):\n",
    "#     for i in range(retries):\n",
    "#         try:\n",
    "#             driver.get(url)\n",
    "#             return driver.page_source\n",
    "#         except Exception as e:\n",
    "#             # print(f\"Error fetching page: {url}, retrying...\")\n",
    "#             # print(e)\n",
    "#             pass\n",
    "#     return None\n",
    "\n",
    "error_logs = []\n",
    "\n",
    "def fetch_page(url, retries=3, timeout=10):\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=timeout)\n",
    "            if response.status_code == 200:\n",
    "                return response.text\n",
    "            else:\n",
    "                error_logs.append({\n",
    "                    'url': url,\n",
    "                    'status_code': response.status_code,\n",
    "                    'error': 'Non-200 status code',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                })\n",
    "        except requests.exceptions.Timeout:\n",
    "            error_logs.append({\n",
    "                'url': url,\n",
    "                'status_code': None,\n",
    "                'error': 'Timeout',\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            })\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            error_logs.append({\n",
    "                'url': url,\n",
    "                'status_code': None,\n",
    "                'error': str(e),\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            })\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: The teams\n",
    "The first step in the logic is to start to set up the data related to the teams. The teams are the 'base unit' of analysis for these data: all meets comprise teams, all gymnasts belong to teams, all scores either belong to gymnasts who belong to teams, or belong to teams directly.\n",
    "\n",
    "On the landing page, I have scraped all the information for the past 10 years; teams are relatively static, but occassionally there will be a new team added to the roster, or a team dropped, so at this stage I'll just grab everything and drop duplicates later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Perhaps wrap this into a method that takes a year?\n",
    "\n",
    "# For every year, access the website and save the data to a json file\n",
    "for year in years:\n",
    "    year_url = year_url_root + str(year)\n",
    "\n",
    "    payload = {}\n",
    "    headers = {\n",
    "        'Cookie': 'PHPSESSID=c48eb24102c0c45390a5d64809741f95'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", year_url, headers=headers, data=payload)\n",
    "\n",
    "    # Save the data to a json file\n",
    "    with open(f'../Data/Raw/teams/{year}_teams.json', 'w') as f:\n",
    "        # pure text\n",
    "        f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the json files into a dataframe\n",
    "\n",
    "# Create an empty dataframe\n",
    "teams_data_df = pd.DataFrame()\n",
    "\n",
    "# For every year, load the data from the json file and append to the dataframe\n",
    "for year in years:\n",
    "    filename = f'../Data/Raw/teams/{year}_teams.json'\n",
    "\n",
    "    # Read the json file into a temporary df\n",
    "    temp_df = pd.read_json(filename)\n",
    "    temp_df['year'] = year\n",
    "\n",
    "    # Append the temporary df to the main df\n",
    "    teams_data_df = pd.concat([teams_data_df, temp_df])\n",
    "\n",
    "\n",
    "teams_data_df = teams_data_df.reset_index(drop=True)\n",
    "teams_df = pd.json_normalize(teams_data_df['data']).reset_index(drop=True)\n",
    "teams_df['year'] = teams_data_df['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns that we are not interested in\n",
    "teams_df = teams_df.drop(columns=['rank', 'ncaa_final', 'nqs', 'regionals', 'rqs', 'division_id', 'average_score', 'high_score', 'ncaa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the df\n",
    "teams_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates - ie. if team_id & team_name are identical, retain years as a list\n",
    "\n",
    "teams_df = teams_df.drop_duplicates(subset=['team_id', 'team_name']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the df\n",
    "teams_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the link to access the team's dashboard\n",
    "base_team_url = 'https://www.roadtonationals.com/api/women/dashboard'\n",
    "\n",
    "# Add the team links to the team_url column\n",
    "teams_df['team_url'] = teams_df.apply(lambda x: f'{base_team_url}/{str(x[\"year\"])}/{str(x[\"team_id\"])}', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the df - this looks good to work with now\n",
    "teams_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we go to each of the links in the teams df and scrape the data for the meets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of desired urls using two list comprehensions\n",
    "base_team_url = 'https://www.roadtonationals.com/api/women/dashboard'\n",
    "\n",
    "# Create a list of all team dashboards across all years and teams \n",
    "# NB: Some of these will be inactive, but we will filter these out later\n",
    "meet_urls = [f'{base_team_url}/{str(year)}/{str(team_id)}' for year in years for team_id in teams_df['team_id']]\n",
    "\n",
    "meet_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the meet info for every team in every year\n",
    "def get_the_meet_info(url):\n",
    "    year = url.split('/')[-2]\n",
    "    team = url.split('/')[-1]\n",
    "    # If we are able to fetch the page without timing out\n",
    "    if fetch_page(url):   \n",
    "        payload = {}\n",
    "        headers = {\n",
    "                'Cookie': 'PHPSESSID=c48eb24102c0c45390a5d64809741f95'\n",
    "                }\n",
    "\n",
    "        response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "        # Save the data to a json file\n",
    "        with open(f'../Data/Raw/meets/{year}_{team}_meets.json', 'w') as f:\n",
    "            # pure text\n",
    "            f.write(response.text)\n",
    "    else:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching up the meet_urls to avoid overloading the server\n",
    "batch_size = 100\n",
    "batches = [meet_urls[i:i + batch_size] for i in range(0, len(meet_urls), batch_size)]\n",
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the method for every url in the list\n",
    "\n",
    "# #Batch 1 #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[0]):\n",
    "\n",
    "#     get_the_meet_info(url)\n",
    "\n",
    "# #Batch 2 #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[1]): \n",
    "\n",
    "#     get_the_meet_info(url)\n",
    "\n",
    "# #Batch 3  #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[2]):\n",
    "\n",
    "#     get_the_meet_info(url)\n",
    "\n",
    "# #Batch 4  #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[3]):\n",
    "\n",
    "#     get_the_meet_info(url)\n",
    "\n",
    "# #Batch 5 #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[4]):\n",
    "\n",
    "#     get_the_meet_info(url)\n",
    "\n",
    "# #Batch 6  #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[5]):\n",
    "\n",
    "#     get_the_meet_info(url)\n",
    "\n",
    "# #Batch 7   #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[6]):\n",
    "\n",
    "#     get_the_meet_info(url)\n",
    "\n",
    "# #Batch 8   #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[7]):\n",
    "\n",
    "#     get_the_meet_info(url)\n",
    "\n",
    "# #Batch 9  #Completed successfully and commented out to avoid re-running\n",
    "# for url in tqdm(batches[8]):\n",
    "\n",
    "#     get_the_meet_info(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the json files into a dataframe\n",
    "\n",
    "# Create an empty dataframe\n",
    "meets_data_df = pd.DataFrame()\n",
    "\n",
    "with open(filename) as data_file:    \n",
    "    data = json.load(data_file)  \n",
    "\n",
    "\n",
    "# For every year, load the data from the json file and append to the dataframe\n",
    "for year in years:\n",
    "    for team in tqdm(team_ids):\n",
    "        filename = f'../Data/Raw/meets/{year}_{team}_meets.json'\n",
    "\n",
    "        with open(filename) as data_file:    \n",
    "            data = json.load(data_file) \n",
    "\n",
    "            # Read the json file into a temporary df\n",
    "            temp_df = pd.json_normalize(data, 'meets')\n",
    "            temp_df['year'] = year\n",
    "            temp_df['team_id'] = team\n",
    "\n",
    "            # Append the temporary df to the main df\n",
    "            meets_data_df = pd.concat([meets_data_df, temp_df])\n",
    "\n",
    "\n",
    "meets_data_df = meets_data_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the df\n",
    "meets_data_df.sort_values(by='meet_id', ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the meet url to the dataframe\n",
    "results_url_root = \"https://www.roadtonationals.com/api/women/meetresults/\"\n",
    "meets_data_df['meet_url'] = meets_data_df['meet_id'].apply(lambda x: f\"{results_url_root}{str(x)}\")\n",
    "meets_data_df.set_index('meet_url').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the website I'm scraping from allocates a different meet_id for the same meet depending on which team is the originating source, so this df has a lot of duplicates that are difficult to spot. Luckily, there are only some 10,000 to sort through, so this should be no problem.\n",
    "\n",
    "I'm in a bit of a rush, so I'm going to leave that problem on the table for now and progress to the next bit of scraping, as it will likely take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_url_root = \"https://www.roadtonationals.com/api/women/meetresults/\"\n",
    "results_links = meets_data_df['meet_url'].tolist()\n",
    "\n",
    "# Get the results info for every meet\n",
    "def get_the_results_info(url):\n",
    "    meet_id = url.split('/')[-1]\n",
    "    # If we are able to fetch the page without timing out\n",
    "    if fetch_page(url):   \n",
    "        payload = {}\n",
    "        headers = {\n",
    "                'Cookie': 'PHPSESSID=c48eb24102c0c45390a5d64809741f95'\n",
    "                }\n",
    "\n",
    "        response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "        # Save the data to a json file\n",
    "        with open(f'../Data/Raw/results/{meet_id}_results.json', 'w') as f:\n",
    "            # pure text\n",
    "            f.write(response.text)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove the first 456 results links as they have already been processed\n",
    "# new_results_links = results_links[1598:]\n",
    "# new_results_links = new_results_links[216:]\n",
    "# new_results_links = new_results_links[376:]\n",
    "# new_results_links = new_results_links[108:]\n",
    "# new_results_links = new_results_links[315:]\n",
    "# new_results_links = new_results_links[90:]\n",
    "\n",
    "# for url in tqdm(new_results_links):\n",
    "\n",
    "#     get_the_results_info(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 1: Go to the url, wait until everything on the page loads\n",
    "\n",
    "def get_url_and_wait_for_elements_to_load(url, css_selector):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        print(\"*****************************\")\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, css_selector)) # (Source: https://selenium-python.readthedocs.io/waits.html )\n",
    "        )\n",
    "        print(element)\n",
    "    except:\n",
    "        print(\"oh no it didn't work\")\n",
    "        pass # ?? Trying to make it so that the program doesn't crash if the element isn't found\n",
    "    \n",
    "\n",
    "get_url_and_wait_for_elements_to_load(url, 'div.rt-table > div.rt-tbody')\n",
    "response = Selector(text=driver.page_source)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2: Set up the dataframes we exported in the last session as variables\n",
    "\n",
    "teams_df = pd.read_csv('../Data/Raw/teams.csv')\n",
    "meets_df = pd.read_csv('../Data/Raw/meets.csv')\n",
    "\n",
    "#print(teams_df)\n",
    "for meet in meets_df['link'][0:20]:\n",
    "    print(meet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css_selector = 'div.rt-tbody'\n",
    "get_url_and_wait_for_elements_to_load(meet_link, css_selector)\n",
    "response = Selector(text=driver.page_source)  \n",
    "meet_results_table = response.css(css_selector)\n",
    "meet_results_table_rows = meet_results_table.css('div.rt-tr-group')\n",
    "teams_button_clicker = driver.find_element(By.CSS_SELECTOR, '#teambtn')\n",
    "row_count = 0\n",
    "meet_host = ''\n",
    "\n",
    "if response.css('p:nth-child(4)').get():\n",
    "    meet_host = response.css('p:nth-child(4)::text').get()\n",
    "else:\n",
    "    meet_host = 'NaN'\n",
    "\n",
    "meet_hosts.append(meet_host)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_url_and_wait_for_elements_to_load(meet_link, css_selector)\n",
    "response = Selector(text=driver.page_source)\n",
    "\n",
    "meet_results_table = response.css(css_selector)\n",
    "meet_results_table.css('div.rt-tr-group::text').getall()\n",
    "\n",
    "meet_results_table_rows.css('div:nth-child(4)::text').getall()\n",
    "len(meet_results_table_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_score_info(url):\n",
    "\n",
    "    #Load the page and set the selectors\n",
    "    get_url_and_wait_for_elements_to_load(url, css_selector)\n",
    "    response = Selector(text=driver.page_source)  \n",
    "    meet_results_table_rows = meet_results_table.css('div.rt-tr-group')\n",
    "\n",
    "    # Determind the meet id\n",
    "    meet_id = url.split('/')[-1]\n",
    "    meet_ids.append(meet_id)\n",
    "    \n",
    "    # Find out if there is a host for the meet, and if so add to the meet_hosts list\n",
    "    meet_host = ''\n",
    "    \n",
    "    if response.css('p:nth-child(4)').get():\n",
    "        meet_host = response.css('p:nth-child(4)::text').get()\n",
    "    else:\n",
    "        meet_host = 'NaN'\n",
    "\n",
    "    meet_hosts.append(meet_host)\n",
    "    \n",
    "    # Find out how many teams are competing in the meet\n",
    "    team_count = len(meet_results_table_rows)\n",
    "\n",
    "    # Add the meet id to the list of team_meet_ids list for each team\n",
    "    for team_meet_id in range(0, team_count):\n",
    "        team_meet_id = meet_id\n",
    "        team_meet_ids.append(team_meet_id)\n",
    "    \n",
    "    # Get the hrefs for each team\n",
    "    team_hrefs = meet_results_table_rows.css('div > div > a::attr(href)').getall()\n",
    "    # Splitting out the team_id and adding them to the team_ids list\n",
    "    for team_href in team_hrefs:\n",
    "        team_id = team_href.split('/')[-1]\n",
    "        team_ids.append(team_id)\n",
    "\n",
    "    # Get the scores for each event and the total meet score (this generates a list of lists)\n",
    "    current_meet_team_vt_scores = meet_results_table_rows.css('div:nth-child(4)::text').getall()\n",
    "    current_meet_team_ub_scores = meet_results_table_rows.css('div:nth-child(5)::text').getall()\n",
    "    current_meet_team_bb_scores = meet_results_table_rows.css('div:nth-child(6)::text').getall()\n",
    "    current_meet_team_fx_scores = meet_results_table_rows.css('div:nth-child(7)::text').getall()\n",
    "    current_meet_team_meet_scores = meet_results_table_rows.css('div:nth-child(8) > strong::text').getall()\n",
    "\n",
    "    # Iterating over the lists generated above and adding them to the appropriate (variable) list\n",
    "    for score in current_meet_team_vt_scores:\n",
    "        team_vt_scores.append(score)\n",
    "    \n",
    "    for score in current_meet_team_ub_scores:\n",
    "        team_ub_scores.append(score)\n",
    "    \n",
    "    for score in current_meet_team_bb_scores:\n",
    "        team_bb_scores.append(score)\n",
    "    \n",
    "    for score in current_meet_team_fx_scores:\n",
    "        team_fx_scores.append(score)\n",
    "    \n",
    "    for score in current_meet_team_meet_scores:\n",
    "        team_meet_scores.append(score)\n",
    "    \n",
    "    \n",
    "    return team_ids, team_meet_ids, team_vt_scores, team_ub_scores, team_bb_scores, team_fx_scores, team_meet_scores, meet_hosts\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gymnast_score_info(url):\n",
    "\n",
    "    #Load the page and set the selectors\n",
    "    get_url_and_wait_for_elements_to_load(url, css_selector)\n",
    "    response = Selector(text=driver.page_source)  \n",
    "    meet_results_table_rows = response.css('div.rt-tr-group')\n",
    "    \n",
    "    # Determind the meet id\n",
    "    meet_id = url.split('/')[-1]\n",
    "    meet_ids.append(meet_id)\n",
    "\n",
    "    # Find out how many teams are competing in the meet\n",
    "    team_count = len(meet_results_table_rows)\n",
    "\n",
    "    #Click the \"Teams\" button\n",
    "    driver.find_element(By.CSS_SELECTOR, '#teambtn').click()\n",
    "    gymnast_results_table_rows = response.css('div.rt-tr-group')\n",
    "\n",
    "    for i in range(0, team_count): # Looping through the teams\n",
    "        # Click on the Team Name\n",
    "        team_clicker_selector = \"#team\" + str(i)\n",
    "        team_clicker = driver.find_element(By.CSS_SELECTOR, team_clicker_selector)\n",
    "        team_clicker.click()\n",
    "\n",
    "        # Get the gymnast metadata\n",
    "        gymnast_hrefs = gymnast_results_table_rows.css('a::attr(href)').getall()\n",
    "        gymnast_names = gymnast_results_table_rows.css('a::text').getall()\n",
    "        \n",
    "        for href in gymnast_hrefs:\n",
    "            gymnast_id = href.split('/')[-1]\n",
    "            gymnast_ids.append(gymnast_id)\n",
    "            gymnast_team_id = href.split('/')[-2]\n",
    "            gymnast_team_ids.append(gymnast_team_id)\n",
    "        \n",
    "        for name in gymnast_names:\n",
    "            gymnast_names.append(name)\n",
    "\n",
    "        # Get the gymnast scores\n",
    "        gymnast_vt_scores = gymnast_results_table_rows.css('div:nth-child(3)::text').getall()\n",
    "        gymnast_ub_scores = gymnast_results_table_rows.css('div:nth-child(4)::text').getall()\n",
    "        gymnast_bb_scores = gymnast_results_table_rows.css('div:nth-child(5)::text').getall()\n",
    "        gymnast_fx_scores = gymnast_results_table_rows.css('div:nth-child(6)::text').getall()\n",
    "        gymnast_aa_scores = gymnast_results_table_rows.css('div:nth-child(7)::text').getall()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    meet_hosts.append(meet_host)\n",
    "    \n",
    "    # Find out how many teams are competing in the meet\n",
    "    team_count = len(meet_results_table_rows)\n",
    "\n",
    "    # Add the meet id to the list of team_meet_ids list for each team\n",
    "    for team_meet_id in range(0, team_count):\n",
    "        team_meet_id = meet_id\n",
    "        team_meet_ids.append(team_meet_id)\n",
    "    \n",
    "    # Get the hrefs for each team\n",
    "    team_hrefs = meet_results_table_rows.css('div > div > a::attr(href)').getall()\n",
    "    # Splitting out the team_id and adding them to the team_ids list\n",
    "    for team_href in team_hrefs:\n",
    "        team_id = team_href.split('/')[-1]\n",
    "        team_ids.append(team_id)\n",
    "\n",
    "    # Get the scores for each event and the total meet score (this generates a list of lists)\n",
    "    current_meet_team_vt_scores = meet_results_table_rows.css('div:nth-child(4)::text').getall()\n",
    "    current_meet_team_ub_scores = meet_results_table_rows.css('div:nth-child(5)::text').getall()\n",
    "    current_meet_team_bb_scores = meet_results_table_rows.css('div:nth-child(6)::text').getall()\n",
    "    current_meet_team_fx_scores = meet_results_table_rows.css('div:nth-child(7)::text').getall()\n",
    "    current_meet_team_meet_scores = meet_results_table_rows.css('div:nth-child(8) > strong::text').getall()\n",
    "\n",
    "    # Iterating over the lists generated above and adding them to the appropriate (variable) list\n",
    "    for score in current_meet_team_vt_scores:\n",
    "        team_vt_scores.append(score)\n",
    "    \n",
    "    for score in current_meet_team_ub_scores:\n",
    "        team_ub_scores.append(score)\n",
    "    \n",
    "    for score in current_meet_team_bb_scores:\n",
    "        team_bb_scores.append(score)\n",
    "    \n",
    "    for score in current_meet_team_fx_scores:\n",
    "        team_fx_scores.append(score)\n",
    "    \n",
    "    for score in current_meet_team_meet_scores:\n",
    "        team_meet_scores.append(score)\n",
    "    \n",
    "    \n",
    "    return team_ids, team_meet_ids, team_vt_scores, team_ub_scores, team_bb_scores, team_fx_scores, team_meet_scores, meet_hosts\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Go to each of the meet's links and scrape the score information\n",
    "\n",
    "# dfs we are adding to: meets_df, team_scores_df (meet_id, team_id), gymnast_scores_df (team_id, meet_id)\n",
    "\n",
    "# Setting up the variables we will be using\n",
    "meet_links = meets_df['link']\n",
    "meet_ids = []\n",
    "team_ids = []\n",
    "team_meet_ids = []\n",
    "team_vt_scores = []\n",
    "team_ub_scores = []\n",
    "team_bb_scores = []\n",
    "team_fx_scores = []\n",
    "team_meet_scores = []\n",
    "gymnast_ids = []\n",
    "gymnast_names = []\n",
    "gymnast_team_ids = []\n",
    "gymnast_meet_ids = []\n",
    "gymnast_vt_scores = []\n",
    "gymnast_ub_scores = []\n",
    "gymnast_bb_scores = []\n",
    "gymnast_fx_scores = []\n",
    "gymnast_aa_scores = []\n",
    "meet_hosts = []\n",
    "\n",
    "meet_hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meet_links[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_meet_links = meet_links[0:100]\n",
    "\n",
    "def get_all_the_team_results_from_all_the_meets(url):\n",
    "    for meet_link in tqdm(meet_links):\n",
    "        #print(meet_link)\n",
    "        get_team_score_info(meet_link)\n",
    "    return team_ids, team_meet_ids, team_vt_scores, team_ub_scores, team_bb_scores, team_fx_scores, team_meet_scores, meet_hosts\n",
    "\n",
    "get_all_the_team_results_from_all_the_meets(url)\n",
    "\n",
    "print(len(team_ids))\n",
    "print(len(team_meet_ids))\n",
    "print(len(team_vt_scores))\n",
    "print(len(team_ub_scores))\n",
    "print(len(team_bb_scores))\n",
    "print(len(team_fx_scores))\n",
    "print(len(team_meet_scores))\n",
    "\n",
    "\n",
    "team_results_df = pd.DataFrame({'team_id': team_ids, 'meet_id': team_meet_ids, 'vt_score': team_vt_scores, 'ub_score': team_ub_scores, 'bb_score': team_bb_scores, 'fx_score': team_fx_scores, 'meet_score': team_meet_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping using hidden APIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace with the actual API endpoint you discovered\n",
    "# years = [2024, 2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016, 2015]\n",
    "\n",
    "# api_url = 'https://www.roadtonationals.com/api/women/finalresults/2024'\n",
    "\n",
    "# # Include necessary headers, cookies, or auth tokens\n",
    "# headers = {}\n",
    "\n",
    "# response = requests.get(api_url, headers=headers)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     data = response.json()\n",
    "#     print(data)\n",
    "# else:\n",
    "#     print(f\"Failed to retrieve data: {response.status_code}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
